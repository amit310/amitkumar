# -*- coding: utf-8 -*-
"""google stock price using RNN and LSTM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fiPx3XCDmcpzRRMC_uQgQLX71kMzxeGV
"""

!pip install tensorflow-gpu==2.0.0-rc0



"""RNN =recurrent neural network-types one to one, one to  many, many to one,many to many, next output is based on previous output of the cell or network.neural network works on the back propagation.two problems occured


vanishing gradient and exploding gradient.
to overcome this problems it needs LSTM n/w special term of RNN.
long short term memory: it consists of many functions and many networks.


steps to build stock prediction mmodel
\data preprocessing
Building RNN
making prediction and visualization
"""

import tensorflow as tf

print(tf.__version__)

from google.colab import drive

drive.mount('/content/drive')

import pandas as pd

data=pd.read_csv('/content/drive/My Drive/GOOG.csv',date_parser=True)
data.tail()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler

data_training=data[data['Date']<'2020-01-01'].copy()
data_training

data_test=data[data['Date']>'2020-01-01'].copy()
data_test

training_data=data_training.drop(['Date','Adj Close'],axis=1)
training_data.head()

scaler=MinMaxScaler()
training_data=scaler.fit_transform(training_data)
training_data#here maximum value is 1

x_train=[]
y_train=[]
# for reading 60 days training data only start from 60 days.then ytrain predict at 60 days

for i in range(60,training_data.shape[0]):
  x_train.append(training_data[i-60:i])
  y_train.append(training_data[i,0])

x_train

x_train=np.array(x_train)
y_train=np.array(y_train)

x_train.shape,y_train.shape

#building RNN model

from tensorflow import keras
from tensorflow.keras.layers import Flatten,Dropout,Dense,BatchNormalization
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Conv1D,MaxPool1D
from tensorflow.keras.optimizers import Adam 
from tensorflow.keras.layers import LSTM

#for continuos value we take regressor


regressor=Sequential()
regressor.add(LSTM(units=60, activation='relu',return_sequences=True,input_shape=(x_train.shape[1],5)))
#each layer has 60x5
regressor.add(Dropout(0.2))

regressor.add(LSTM(units=80, activation='relu',return_sequences=True))
regressor.add(Dropout(0.2))


regressor.add(LSTM(units=80, activation='relu',return_sequences=True))
regressor.add(Dropout(0.2))

regressor.add(LSTM(units=120, activation='relu'))
regressor.add(Dropout(0.2))


regressor.add(Dense(units=1))

regressor.summary()

regressor.compile(optimizer='Adam',loss='mean_squared_error')

regressor.fit(x_train,y_train,epochs=50
              ,batch_size=32)





#now prepare for test dataset

data_test.head()

data_training.tail(60)

past_60_days=data_training.tail(60)

df=past_60_days.append(data_test,ignore_index=True)
df

df=df.drop(['Date','Adj Close'],axis=1)

df.head()

inputs=scaler.transform(df)
inputs

x_test=[]
y_test=[]

for i in range(60, inputs.shape[0]):
  x_test.append(inputs[i-60:i])
  y_test.append(inputs[i,0])

x_test=np.array(x_test)
y_test=np.array(y_test)

x_test

y_pred=regressor.predict(x_test)
y_pred #these are scaled valued

y_test

scaler.scale_

scale=1/7.61069658e-04
scale

y_pred=y_pred*scale
y_test=y_test*scale

y_pred

y_test

#now visualization

plt.figure(figsize=(14,5))
 plt.plot(y_test,color='red',label='Real google stock price')
 plt.plot(y_pred,color='green',label='Predicted google stock price')
 plt.title('Google stock price prediction')
 plt.xlabel('Times')
 plt.ylabel('Google Stock Price')
 plt.legend()
 plt.show()





#for building new LSTM model for getting low loss

regressor=Sequential()
regressor.add(LSTM(units=60, activation='relu',return_sequences=True,input_shape=(x_train.shape[1],5)))
#each layer has 60x5
regressor.add(Dropout(0.2))

regressor.add(LSTM(units=80, activation='relu',return_sequences=True))
regressor.add(Dropout(0.2))


regressor.add(LSTM(units=80, activation='relu',return_sequences=True))
regressor.add(Dropout(0.2))

regressor.add(LSTM(units=120, activation='relu'))
regressor.add(Dropout(0.2))


regressor.add(Dense(units=1))